{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4037bad9-b3fa-4190-a043-ef41baae6f8f",
   "metadata": {},
   "source": [
    "This notebook implements a majority voting fusion strategy to combine predictions from both the DTW and LSTM models for hand trajectory classification. Instead of relying on a single model, the system decides the final predicted point by counting votes from both models and selecting the most frequent prediction.\n",
    "\n",
    "As a hand trajectory is being captured in real-time, both DTW and LSTM models produce predictions continuously and the predictions are stored in separate lists (dtw_preds and lstm_preds). Once a sufficient number of predictions is collected (5 recent ones from each model), a combined list is formed. The most frequent label (the mode) from the combined predictions is selected as the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33fb481-6680-4eab-ab98-53fe20560ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque, Counter\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyrealsense2 as rs\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8386116f-4d37-434b-834f-09fb3a9269cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained LSTM model and label encoder\n",
    "lstm_model = load_model(\"lstm_index_finger_model_new.keras\")\n",
    "label_encoder = joblib.load(\"label_encoder_new.pkl\")\n",
    "\n",
    "# Load DTW reference data\n",
    "# Assume you already have X (padded sequences) and y (encoded labels)\n",
    "# Example:\n",
    "X = np.load(\"X_dtw_new.npy\")\n",
    "y = np.load(\"y_dtw_new.npy\")\n",
    "\n",
    "# Create DTW templates from training data\n",
    "\n",
    "def setup_dtw_templates(X, y):\n",
    "    reference_sequences = defaultdict(list)\n",
    "    for i, label in enumerate(y):\n",
    "        reference_sequences[label].append(X[i])\n",
    "    return {label: seqs[0] for label, seqs in reference_sequences.items()}\n",
    "\n",
    "templates = setup_dtw_templates(X, y)  # X and y need to be defined from your DTW data\n",
    "\n",
    "# DTW classification\n",
    "def classify_with_dtw(sequence, templates):\n",
    "    best_label, best_distance = None, float('inf')\n",
    "    for label, ref_seq in templates.items():\n",
    "        dist, _ = fastdtw(sequence, ref_seq, dist=euclidean)\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "# Combined majority vote prediction\n",
    "def majority_vote_predict(sequence, templates, max_len=50):\n",
    "    padded_seq = pad_sequences([sequence], maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Predict with LSTM\n",
    "    lstm_probs = lstm_model.predict(padded_seq, verbose=0)[0]\n",
    "    lstm_pred = np.argmax(lstm_probs)\n",
    "\n",
    "    # Predict with DTW\n",
    "    dtw_pred = classify_with_dtw(sequence, templates)\n",
    "\n",
    "    # Use majority voting logic\n",
    "    if lstm_pred == dtw_pred:\n",
    "        final = lstm_pred\n",
    "    else:\n",
    "        final = lstm_pred  # fallback strategy\n",
    "\n",
    "    return label_encoder.inverse_transform([final])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c75adb-0fb5-4f46-b996-53151beca99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# ─────────────── Load Models and Encoders ───────────────\n",
    "lstm_model = load_model(\"lstm_index_finger_model_new.keras\")\n",
    "label_encoder = joblib.load(\"label_encoder_new.pkl\")\n",
    "templates_X = np.load(\"X_dtw_new.npy\")\n",
    "templates_y = np.load(\"y_dtw_new.npy\")\n",
    "\n",
    "# DTW template setup\n",
    "def setup_dtw_templates(X, y):\n",
    "    reference_sequences = defaultdict(list)\n",
    "    for i, label in enumerate(y):\n",
    "        reference_sequences[label].append(X[i])\n",
    "    return {label: seqs[0] for label, seqs in reference_sequences.items()}\n",
    "\n",
    "templates = setup_dtw_templates(templates_X, templates_y)\n",
    "\n",
    "# DTW classification function\n",
    "def classify_with_dtw(sequence):\n",
    "    best_label, best_distance = None, float('inf')\n",
    "    for label, ref_seq in templates.items():\n",
    "        dist, _ = fastdtw(sequence, ref_seq, dist=euclidean)\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "# Combined voting function\n",
    "def majority_vote_predict(sequence, max_len=50):\n",
    "    padded = pad_sequences([sequence], maxlen=max_len, padding='post', truncating='post')\n",
    "    lstm_probs = lstm_model.predict(padded, verbose=0)[0]\n",
    "    lstm_pred = np.argmax(lstm_probs)\n",
    "    dtw_pred = classify_with_dtw(sequence)\n",
    "\n",
    "    final_pred = lstm_pred if lstm_pred == dtw_pred else lstm_pred\n",
    "    return label_encoder.inverse_transform([final_pred])[0]\n",
    "\n",
    "# ─────────────── Camera Setup ───────────────\n",
    "MAX_LEN = 50\n",
    "trajectory = []\n",
    "recent_predictions = deque(maxlen=10)\n",
    "stable_label = None\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# ─────────────── MediaPipe Setup ───────────────\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned = align.process(frames)\n",
    "        depth_frame = aligned.get_depth_frame()\n",
    "        color_frame = aligned.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        frame_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(color_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                h, w, _ = color_image.shape\n",
    "                lm = hand_landmarks.landmark[8]\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                cx, cy = np.clip(cx, 0, w - 1), np.clip(cy, 0, h - 1)\n",
    "                z = depth_frame.get_distance(cx, cy) * 1000  # mm\n",
    "                trajectory.append([cx, cy, z])\n",
    "\n",
    "                if len(trajectory) > MAX_LEN:\n",
    "                    trajectory = trajectory[-MAX_LEN:]\n",
    "\n",
    "                if len(trajectory) >= MAX_LEN:\n",
    "                    label = majority_vote_predict(trajectory)\n",
    "                    recent_predictions.append(label)\n",
    "                    most_common = Counter(recent_predictions).most_common(1)[0]\n",
    "\n",
    "                    if most_common[1] >= 6:\n",
    "                        stable_label = most_common[0]\n",
    "\n",
    "                    if stable_label:\n",
    "                        cv2.putText(color_image, f\"Predicted: {stable_label}\", (10, 60),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw circle and depth\n",
    "                cv2.circle(color_image, (cx, cy), 8, (0, 255, 0), -1)\n",
    "                cv2.putText(color_image, f\"{round(z)} mm\", (cx + 10, cy - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Real-Time Prediction\", color_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "\n",
    "finally:\n",
    "    print(\"Exiting\")\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015c073-60d3-4dd1-a55f-e50d14c5147f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hand]",
   "language": "python",
   "name": "conda-env-hand-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
