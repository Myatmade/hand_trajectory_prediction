{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f888778-d57e-43bc-ae6a-51764a07aecd",
   "metadata": {},
   "source": [
    "This program is for gesture classification using DTW. The goal is to compare a new hand trajectory obtained from live input to a set of pre-recorded reference sequences from the csv file and identify which predefined target or point it most closely resembles. It also saves the model and contains the performance metrics and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bac507a-438b-4462-9c8d-c1d7586bc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyrealsense2 as rs\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eec2242d-6c0c-4305-9ba8-17472875c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       1.00      1.00      1.00         6\n",
      "          P2       1.00      1.00      1.00         6\n",
      "          P3       1.00      1.00      1.00         6\n",
      "          P4       1.00      1.00      1.00         6\n",
      "          P5       1.00      1.00      1.00         6\n",
      "          P6       1.00      1.00      1.00         6\n",
      "          P7       1.00      1.00      1.00         6\n",
      "          P8       1.00      1.00      1.00         6\n",
      "          P9       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6 0 0 0 0 0 0 0 0]\n",
      " [0 6 0 0 0 0 0 0 0]\n",
      " [0 0 6 0 0 0 0 0 0]\n",
      " [0 0 0 6 0 0 0 0 0]\n",
      " [0 0 0 0 6 0 0 0 0]\n",
      " [0 0 0 0 0 6 0 0 0]\n",
      " [0 0 0 0 0 0 6 0 0]\n",
      " [0 0 0 0 0 0 0 6 0]\n",
      " [0 0 0 0 0 0 0 0 6]]\n",
      "Input shape (X): (135, 79, 3)\n",
      "Target shape (y): (135,)\n",
      "Classes: ['P1' 'P2' 'P3' 'P4' 'P5' 'P6' 'P7' 'P8' 'P9']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"hand_trajectory_labeled_new_edit.csv\")\n",
    "\n",
    "# Normalize x, y, z\n",
    "scaler = MinMaxScaler()\n",
    "df[['x_px', 'y_px', 'z_mm']] = scaler.fit_transform(df[['x_px', 'y_px', 'z_mm']])\n",
    "\n",
    "# Group by point and sequence ID\n",
    "grouped = df.groupby(['point_id', 'sequence_id'])\n",
    "\n",
    "# Get the maximum sequence length dynamically\n",
    "max_len = grouped.size().max()\n",
    "\n",
    "# Prepare sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for (point_id, sequence_id), group in grouped:\n",
    "    seq = group[['x_px', 'y_px', 'z_mm']].values\n",
    "    sequences.append(seq)\n",
    "    labels.append(point_id)\n",
    "\n",
    "# Pad sequences to the max length\n",
    "X = pad_sequences(sequences, maxlen=max_len, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Encode labels to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "\n",
    "# Build templates from training data only\n",
    "reference_sequences = defaultdict(list)\n",
    "for i, label in enumerate(y_train):\n",
    "    reference_sequences[label].append(X_train[i])\n",
    "templates = {label: seqs[0] for label, seqs in reference_sequences.items()}\n",
    "\n",
    "# DTW classification function\n",
    "def classify_with_dtw(sequence):\n",
    "    best_label, best_distance = None, float('inf')\n",
    "    for label, ref_seq in templates.items():\n",
    "        dist, _ = fastdtw(sequence, ref_seq, dist=euclidean)\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = [classify_with_dtw(seq) for seq in X_test]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print info\n",
    "print(\"Input shape (X):\", X.shape)\n",
    "print(\"Target shape (y):\", y.shape)\n",
    "print(\"Classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d3a9bab-064a-4bb6-b54a-9a3836281de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_dtw_new.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save arrays and encoder\n",
    "np.save(\"X_dtw_new.npy\", X)\n",
    "np.save(\"Y_dtw_new.npy\", y)\n",
    "joblib.dump(label_encoder, \"label_encoder_dtw_new.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a56a025-83ee-46c9-80c4-e4d3f677036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start moving hand — press 's' to stop recording\n",
      "Predicted target point: P7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goga_\\anaconda3\\envs\\hand\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Setup RealSense ===\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# === Setup MediaPipe Hands ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1,\n",
    "                       min_detection_confidence=0.7,\n",
    "                       min_tracking_confidence=0.5)\n",
    "\n",
    "# === Capture Sequence ===\n",
    "print(\"Start moving hand — press 's' to stop recording\")\n",
    "sequence = []\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    aligned = align.process(frames)\n",
    "    depth_frame = aligned.get_depth_frame()\n",
    "    color_frame = aligned.get_color_frame()\n",
    "    if not depth_frame or not color_frame:\n",
    "        continue\n",
    "\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            h, w, _ = color_image.shape\n",
    "            landmark = hand_landmarks.landmark[8]  # Index fingertip\n",
    "            cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "            cx = np.clip(cx, 0, w - 1)\n",
    "            cy = np.clip(cy, 0, h - 1)\n",
    "            z = depth_frame.get_distance(cx, cy) * 1000  # in mm\n",
    "\n",
    "            if z > 0:  # Ignore invalid points\n",
    "                sequence.append([cx, cy, z])\n",
    "\n",
    "            # Visual feedback\n",
    "            cv2.circle(color_image, (cx, cy), 8, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.putText(color_image, f\"Recording ({len(sequence)} frames)...\",\n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    cv2.imshow(\"Live Input\", color_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break\n",
    "\n",
    "pipeline.stop()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()\n",
    "\n",
    "# === Normalize & Pad the new sequence ===\n",
    "new_seq = np.array(sequence)\n",
    "if new_seq.shape[0] == 0:\n",
    "    print(\"No valid data captured.\")\n",
    "    exit()\n",
    "\n",
    "# Normalize using the same scaler\n",
    "new_seq_scaled = scaler.transform(new_seq)\n",
    "\n",
    "# Pad to match training sequence length\n",
    "new_seq_padded = pad_sequences([new_seq_scaled], maxlen=X.shape[1],\n",
    "                               dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# === DTW Classification ===\n",
    "def classify_with_dtw(sequence):\n",
    "    best_label, best_distance = None, float('inf')\n",
    "    for label, ref_seq in templates.items():\n",
    "        dist, _ = fastdtw(sequence, ref_seq, dist=euclidean)\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "matched_label = classify_with_dtw(new_seq_padded[0])\n",
    "matched_name = label_encoder.inverse_transform([matched_label])[0]\n",
    "\n",
    "print(f\"Predicted target point: {matched_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed415dd5-e772-4fcb-a4da-6444e0c3f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hand]",
   "language": "python",
   "name": "conda-env-hand-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
