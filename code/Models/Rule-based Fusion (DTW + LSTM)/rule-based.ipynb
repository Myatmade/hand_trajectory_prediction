{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d991767-9235-4776-ab2f-6a03bef6a9c9",
   "metadata": {},
   "source": [
    "This notebook implements a rule-based decision fusion system that combines predictions from two models: DTW and LSTM, to classify hand trajectory sequences. The aim is to use the strengths of both models by switching between them based on certain heuristics.\n",
    "\n",
    "At the beginning of the hand movement, DTW is used to make the first prediction as DTW typically performs well early in the gesture.\n",
    "\n",
    "Then, once the sequence length crosses a certain threshold (more than 50 frames), the system checks if the LSTM prediction is stable (repeated same label for the last few predictions).\n",
    "\n",
    "If LSTM predictions stabilize, the model switches to use LSTM as the final decision maker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3f816e-ba94-46e3-b85f-260e5ee361f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict, deque, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c2429f-7367-4a97-a1a9-cebf6b1b5d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# ─────────────── Load Models and Encoders ───────────────\n",
    "lstm_model = load_model(\"lstm_index_finger_model_new.keras\")\n",
    "label_encoder = joblib.load(\"label_encoder_new.pkl\")\n",
    "templates_X = np.load(\"X_dtw_new.npy\")\n",
    "templates_y = np.load(\"y_dtw_new.npy\")\n",
    "\n",
    "# DTW setup\n",
    "def setup_dtw_templates(X, y):\n",
    "    ref = defaultdict(list)\n",
    "    for i, label in enumerate(y):\n",
    "        ref[label].append(X[i])\n",
    "    return {label: seqs[0] for label, seqs in ref.items()}\n",
    "\n",
    "templates = setup_dtw_templates(templates_X, templates_y)\n",
    "\n",
    "def classify_with_dtw(sequence):\n",
    "    best_label, best_distance = None, float('inf')\n",
    "    for label, ref_seq in templates.items():\n",
    "        dist, _ = fastdtw(sequence, ref_seq, dist=euclidean)\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "# ─────────────── Rule-Based Fusion ───────────────\n",
    "def use_lstm(trajectory, threshold=5.0):\n",
    "    \"\"\"Return True if movement is stable based on low variance.\"\"\"\n",
    "    traj_np = np.array(trajectory)\n",
    "    if len(traj_np) < 10:\n",
    "        return False\n",
    "    last_part = traj_np[-10:]\n",
    "    var = np.var(last_part, axis=0)  # variance in x, y, z\n",
    "    return np.all(var < threshold)\n",
    "\n",
    "def predict_lstm(sequence, max_len=50):\n",
    "    padded = pad_sequences([sequence], maxlen=max_len, padding='post', truncating='post')\n",
    "    probs = lstm_model.predict(padded, verbose=0)[0]\n",
    "    return np.argmax(probs)\n",
    "\n",
    "# ─────────────── Camera and Hand Setup ───────────────\n",
    "MAX_LEN = 50\n",
    "trajectory = []\n",
    "recent_predictions = deque(maxlen=10)\n",
    "stable_label = None\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned = align.process(frames)\n",
    "        depth_frame = aligned.get_depth_frame()\n",
    "        color_frame = aligned.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        frame_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(color_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                h, w, _ = color_image.shape\n",
    "                lm = hand_landmarks.landmark[8]\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                cx, cy = np.clip(cx, 0, w - 1), np.clip(cy, 0, h - 1)\n",
    "                z = depth_frame.get_distance(cx, cy) * 1000  # mm\n",
    "                trajectory.append([cx, cy, z])\n",
    "\n",
    "                if len(trajectory) > MAX_LEN:\n",
    "                    trajectory = trajectory[-MAX_LEN:]\n",
    "\n",
    "                if len(trajectory) >= MAX_LEN:\n",
    "                    if use_lstm(trajectory):\n",
    "                        pred_idx = predict_lstm(trajectory)\n",
    "                    else:\n",
    "                        pred_idx = classify_with_dtw(trajectory)\n",
    "\n",
    "                    label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "                    recent_predictions.append(label)\n",
    "                    most_common = Counter(recent_predictions).most_common(1)[0]\n",
    "\n",
    "                    if most_common[1] >= 6:\n",
    "                        stable_label = most_common[0]\n",
    "\n",
    "                    if stable_label:\n",
    "                        cv2.putText(color_image, f\"Predicted: {stable_label}\", (10, 60),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.circle(color_image, (cx, cy), 8, (0, 255, 0), -1)\n",
    "                cv2.putText(color_image, f\"{round(z)} mm\", (cx + 10, cy - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Real-Time Prediction\", color_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "\n",
    "finally:\n",
    "    print(\"Exiting\")\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f9879-d1cf-4386-88e4-6f73090a5a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hand]",
   "language": "python",
   "name": "conda-env-hand-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
